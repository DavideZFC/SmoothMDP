{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes.environments.PendulumSimple import PendulumSimple\n",
    "from classes.agents.FD_LSVI import FD_LSVI\n",
    "from functions.misc.test_algorithm_after_learning import test_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal design found: before squeezing 21.75177667567862, after squeezing 31.020218121595224\n",
      "(296, 3)\n",
      "(296, 20)\n",
      "(296,)\n",
      "(296, 2)\n",
      "(5,)\n",
      "step 19 done\n",
      "step 18 done\n",
      "step 17 done\n",
      "step 16 done\n",
      "step 15 done\n",
      "step 14 done\n",
      "step 13 done\n",
      "step 12 done\n",
      "step 11 done\n",
      "step 10 done\n",
      "step 9 done\n",
      "step 8 done\n",
      "step 7 done\n",
      "step 6 done\n",
      "step 5 done\n",
      "step 4 done\n",
      "step 3 done\n",
      "step 2 done\n",
      "step 1 done\n",
      "step 0 done\n"
     ]
    }
   ],
   "source": [
    "env = PendulumSimple()\n",
    "agent = FD_LSVI(env)\n",
    "state_disc = 40\n",
    "action_disc = 5\n",
    "agent.get_datasets(disc_numbers=[state_disc, state_disc, action_disc])\n",
    "agent.compute_q_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.48791306e-03, -3.06048765e-03, -2.96137430e-01, -4.32042314e-03,\n",
       "       -6.81454078e-03,  1.25321724e-02,  7.18952145e-03, -5.63145431e-03,\n",
       "        5.40551356e-03, -1.33621286e-03,  1.05101530e-02, -2.95223948e-01,\n",
       "        2.92146203e-03, -3.30402958e-04, -8.31735974e-03, -9.46615653e-04,\n",
       "        2.65255627e+01, -6.44603907e-03, -7.06493668e-03,  4.66283530e-03])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.w_vectors[-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current state: [-0.06956029 -0.667235  ], current action: [0.], current reward: 0.9507042014385455\n",
      "current state: [-0.08276746 -0.10372891], current action: [-0.5], current reward: 0.9911629049203963\n",
      "current state: [-0.08987461 -0.05581938], current action: [-0.5], current reward: 0.9907163005092164\n",
      "current state: [-0.09647603 -0.05184737], current action: [-0.5], current reward: 0.9895449293762895\n",
      "current state: [-0.10325123 -0.05321241], current action: [-0.5], current reward: 0.9881950383379778\n",
      "current state: [-0.11028984 -0.05528107], current action: [-0.5], current reward: 0.9866891624459231\n",
      "current state: [-0.1176106  -0.05749712], current action: [-0.5], current reward: 0.9850175209153421\n",
      "current state: [-0.12522376 -0.05979353], current action: [-0.5], current reward: 0.9831659586522937\n",
      "current state: [-0.13313842 -0.06216164], current action: [-0.5], current reward: 0.9811188921659642\n",
      "current state: [-0.14136346 -0.06459931], current action: [-0.5], current reward: 0.9788596436359022\n",
      "current state: [-0.1499075 -0.0671047], current action: [-0.5], current reward: 0.9763704675054666\n",
      "current state: [-0.15877885 -0.06967542], current action: [-0.5], current reward: 0.9736325490929996\n",
      "current state: [-0.16798542 -0.07230833], current action: [-0.5], current reward: 0.970626011805724\n",
      "current state: [-0.17753465 -0.07499951], current action: [-0.5], current reward: 0.9673299399069397\n",
      "current state: [-0.18743335 -0.07774413], current action: [-0.5], current reward: 0.9637224203334599\n",
      "current state: [-0.19768757 -0.0805364 ], current action: [-0.5], current reward: 0.9597806067917919\n",
      "current state: [-0.2083025  -0.08336947], current action: [-0.5], current reward: 0.9554808094222843\n",
      "current state: [-0.21928233 -0.08623536], current action: [-0.5], current reward: 0.950798613333147\n",
      "current state: [-0.23063006 -0.0891249 ], current action: [-0.5], current reward: 0.9457090291963907\n",
      "current state: [-0.24234739 -0.09202767], current action: [-0.5], current reward: 0.9401866788260507\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()[0]\n",
    "done = False\n",
    "h = 0\n",
    "episodic_return = 0\n",
    "\n",
    "while not done:\n",
    "    # action = env.action_space.sample()\n",
    "    action = agent.choose_action(state, h)\n",
    "\n",
    "    next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "    print('current state: {}, current action: {}, current reward: {}'.format(state, action, reward))\n",
    "    inutile = input()\n",
    "    episodic_return += reward\n",
    "\n",
    "    done = terminated or truncated\n",
    "    state = next_state\n",
    "    h += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.168026350790523"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = 1355\n",
    "((x + np.pi) % (2 * np.pi)) - np.pi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
